{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Model, load_model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_values, \n",
    "                             transaction_ids, \n",
    "                             out_file=\"submission.csv\", \n",
    "                             target='isFraud', \n",
    "                             index_label=\"TransactionID\"):\n",
    "    \n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_values,\n",
    "                                index = transaction_ids,\n",
    "                                columns=[target])\n",
    "    \n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 394)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Train data\n",
    "df = pd.read_csv(\"train_transaction.csv\")\n",
    "train_size = df.shape[0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 393)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Test data\n",
    "df_test = pd.read_csv(\"test_transaction.csv\")\n",
    "test_size = df_test.shape[0]\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "\n",
       "   card2  card3       card4  card5  ...  V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "\n",
       "[3 rows x 394 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"isFraud\"]\n",
    "\n",
    "del df[\"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590540"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Train and Test data\n",
    "df = pd.concat([df, df_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling for Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransactionDT\n",
    "#df.TransactionDT.isna().sum()\n",
    "\n",
    "df[\"DTSec\"] = df.TransactionDT % 60\n",
    "df[\"DTMin\"] = (df.TransactionDT % 3600) // 60\n",
    "df[\"DTHour\"] = (df.TransactionDT % 86400) // 3600\n",
    "df[\"DTDow\"] = (df.TransactionDT % 604800) // 86400\n",
    "\n",
    "del df['TransactionDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransactionAmt\n",
    "#df.TransactionAmt.isna().sum()\n",
    "# No changes at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ProductCD\n",
    "#df.ProductCD.isna().sum()\n",
    "#df.ProductCD.value_counts()\n",
    "\n",
    "df = pd.get_dummies(df, columns=['ProductCD'], prefix='ProductCD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# card1\n",
    "#df.card1.isna().sum()\n",
    "# No changes at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# card2\n",
    "#df.card2.isna().sum()\n",
    "#df.card2.min()\n",
    "\n",
    "df[\"card2_nan\"] = df.card2.isna().astype(int)\n",
    "df.card2.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# card3\n",
    "#df.card3.isna().sum()\n",
    "#df.card3.min()\n",
    "\n",
    "df[\"card3_nan\"] = df.card3.isna().astype(int)\n",
    "df.card3.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# card4\n",
    "#df.card4.isna().sum()\n",
    "\n",
    "df = pd.get_dummies(df, columns=['card4'], prefix='card4', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# card5\n",
    "#df.card5.isna().sum()\n",
    "#df.card5.min()\n",
    "\n",
    "df[\"card5_nan\"] = df.card5.isna().astype(int)\n",
    "df.card5.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# card6\n",
    "#df.card6.isna().sum()\n",
    "\n",
    "df = pd.get_dummies(df, columns=['card6'], prefix='card6', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addr1\n",
    "#df.addr1.isna().sum()\n",
    "\n",
    "df[\"addr1_nan\"] = df.addr1.isna().astype(int)\n",
    "df.addr1.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addr2\n",
    "#df.addr2.isna().sum()\n",
    "#df.addr2.value_counts()\n",
    "#df.addr2.min()\n",
    "\n",
    "df[\"addr2_nan\"] = df.addr2.isna().astype(int)\n",
    "df.addr2.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist1\n",
    "#df.dist1\n",
    "\n",
    "df[\"dist1_nan\"] = df.dist1.isna().astype(int)\n",
    "df.dist1.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist2\n",
    "#df.dist2.min()\n",
    "\n",
    "df[\"dist2_nan\"] = df.dist2.isna().astype(int)\n",
    "df.dist2.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_emaildomain\n",
    "#df.P_emaildomain\n",
    "\n",
    "df = pd.get_dummies(df, columns=['P_emaildomain'], prefix='P_emaildomain', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_emaildomain\n",
    "#df.R_emaildomain\n",
    "\n",
    "df = pd.get_dummies(df, columns=['R_emaildomain'], prefix='R_emaildomain', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1\n",
    "#df.C1.isna().sum()\n",
    "#df.C1.value_counts()\n",
    "\n",
    "df[\"C1_nan\"] = df.C1.isna().astype(int)\n",
    "df.C1.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2\n",
    "#df.C2.isna().sum()\n",
    "#df.C2.value_counts()\n",
    "\n",
    "df[\"C2_nan\"] = df.C2.isna().astype(int)\n",
    "df.C2.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C3\n",
    "#df.C3.isna().sum()\n",
    "#df.C3.value_counts()\n",
    "\n",
    "df[\"C3_nan\"] = df.C3.isna().astype(int)\n",
    "df.C3.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4\n",
    "#df.C4.isna().sum()\n",
    "#df.C4.value_counts()\n",
    "\n",
    "df[\"C4_nan\"] = df.C4.isna().astype(int)\n",
    "df.C4.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C5\n",
    "#df.C5.isna().sum()\n",
    "#df.C5.value_counts()\n",
    "\n",
    "df[\"C5_nan\"] = df.C5.isna().astype(int)\n",
    "df.C5.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C6\n",
    "#df.C6\n",
    "#df.C6.isna().sum()\n",
    "#df.C6.value_counts()\n",
    "\n",
    "df[\"C6_nan\"] = df.C6.isna().astype(int)\n",
    "df.C6.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C7\n",
    "#df.C7\n",
    "#df.C7.isna().sum()\n",
    "#df.C7.value_counts()\n",
    "\n",
    "df[\"C7_nan\"] = df.C7.isna().astype(int)\n",
    "df.C7.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C8\n",
    "#df.C8\n",
    "#df.C8.isna().sum()\n",
    "#df.C8.value_counts()\n",
    "\n",
    "df[\"C8_nan\"] = df.C8.isna().astype(int)\n",
    "df.C8.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C9\n",
    "#df.C9\n",
    "#df.C9.isna().sum()\n",
    "#df.C9.value_counts()\n",
    "\n",
    "df[\"C9_nan\"] = df.C9.isna().astype(int)\n",
    "df.C9.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C10\n",
    "#df.C10\n",
    "#df.C10.isna().sum()\n",
    "#df.C10.value_counts()\n",
    "\n",
    "df[\"C10_nan\"] = df.C10.isna().astype(int)\n",
    "df.C10.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C11\n",
    "#df.C11\n",
    "#df.C11.isna().sum()\n",
    "#df.C11.value_counts()\n",
    "\n",
    "df[\"C11_nan\"] = df.C11.isna().astype(int)\n",
    "df.C11.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C12\n",
    "#df.C12\n",
    "#df.C12.isna().sum()\n",
    "#df.C12.value_counts()\n",
    "\n",
    "df[\"C12_nan\"] = df.C12.isna().astype(int)\n",
    "df.C12.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C13\n",
    "#df.C13\n",
    "#df.C13.isna().sum()\n",
    "#df.C13.value_counts()\n",
    "\n",
    "df[\"C13_nan\"] = df.C13.isna().astype(int)\n",
    "df.C13.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C14\n",
    "#df.C14\n",
    "#df.C14.isna().sum()\n",
    "#df.C14.value_counts()\n",
    "\n",
    "df[\"C14_nan\"] = df.C14.isna().astype(int)\n",
    "df.C14.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1\n",
    "#df.D1\n",
    "#df.D1.isna().sum()\n",
    "\n",
    "df[\"D1_nan\"] = df.D1.isna().astype(int)\n",
    "df.D1.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D2\n",
    "#df.D2\n",
    "#df.D2.min()\n",
    "\n",
    "df[\"D2_nan\"] = df.D2.isna().astype(int)\n",
    "df.D2.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D3\n",
    "#df.D3\n",
    "\n",
    "df[\"D3_nan\"] = df.D3.isna().astype(int)\n",
    "df.D3.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D4\n",
    "#df.D4\n",
    "\n",
    "df[\"D4_nan\"] = df.D4.isna().astype(int)\n",
    "df.D4.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D5\n",
    "#df.D5\n",
    "\n",
    "df[\"D5_nan\"] = df.D5.isna().astype(int)\n",
    "df.D5.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D6\n",
    "#df.D6\n",
    "#df.D6.value_counts()\n",
    "\n",
    "df[\"D6_nan\"] = df.D6.isna().astype(int)\n",
    "df.D6.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D7\n",
    "#df.D7\n",
    "#df.D7.value_counts()\n",
    "\n",
    "df[\"D7_nan\"] = df.D7.isna().astype(int)\n",
    "df.D7.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D8\n",
    "#df.D8\n",
    "#df.D8.value_counts()\n",
    "\n",
    "df[\"D8_nan\"] = df.D8.isna().astype(int)\n",
    "df.D8.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D9\n",
    "#df.D9\n",
    "#df.D9.value_counts()\n",
    "\n",
    "df[\"D9_nan\"] = df.D9.isna().astype(int)\n",
    "df.D9.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D10\n",
    "#df.D10\n",
    "\n",
    "df[\"D10_nan\"] = df.D10.isna().astype(int)\n",
    "df.D10.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D11\n",
    "#df.D11\n",
    "\n",
    "df[\"D11_nan\"] = df.D11.isna().astype(int)\n",
    "df.D11.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D12\n",
    "#df.D12\n",
    "#df.D12.value_counts()\n",
    "\n",
    "df[\"D12_nan\"] = df.D12.isna().astype(int)\n",
    "df.D12.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D13\n",
    "#df.D13\n",
    "#df.D13.value_counts()\n",
    "\n",
    "df[\"D13_nan\"] = df.D13.isna().astype(int)\n",
    "df.D13.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D14\n",
    "#df.D14\n",
    "#df.D14.value_counts()\n",
    "\n",
    "df[\"D14_nan\"] = df.D14.isna().astype(int)\n",
    "df.D14.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D15\n",
    "#df.D15\n",
    "\n",
    "df[\"D15_nan\"] = df.D15.isna().astype(int)\n",
    "df.D15.fillna(-1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M1\n",
    "#df.M1\n",
    "#df.M1.value_counts()\n",
    "\n",
    "df = pd.get_dummies(df, columns=['M1'], prefix='M1', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M2\n",
    "#df.M2\n",
    "#df.M2.value_counts()\n",
    "\n",
    "df = pd.get_dummies(df, columns=['M2'], prefix='M2', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M3\n",
    "#df.M3\n",
    "\n",
    "df = pd.get_dummies(df, columns=['M3'], prefix='M3', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M4\n",
    "#df.M4\n",
    "#df.M4.value_counts()\n",
    "\n",
    "df = pd.get_dummies(df, columns=['M4'], prefix='M4', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M5\n",
    "#df.M5\n",
    "\n",
    "df = pd.get_dummies(df, columns=['M5'], prefix='M5', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M6\n",
    "#df.M6\n",
    "\n",
    "df = pd.get_dummies(df, columns=['M6'], prefix='M6', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M7\n",
    "#df.M7\n",
    "\n",
    "df = pd.get_dummies(df, columns=['M7'], prefix='M7', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M8\n",
    "#df.M8\n",
    "\n",
    "df = pd.get_dummies(df, columns=['M8'], prefix='M8', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M9\n",
    "#df.M9\n",
    "\n",
    "df = pd.get_dummies(df, columns=['M9'], prefix='M9', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Process all V-columns at once\n",
    "#\n",
    "\n",
    "MAX_AMOUNT_OF_UNIQUE = 16\n",
    "\n",
    "for i in range(1, 340):\n",
    "    col = \"V\" + str(i)\n",
    "    \n",
    "    if (len(df[col].value_counts()) > MAX_AMOUNT_OF_UNIQUE):\n",
    "        df[col + \"_nan\"] = df[col].isna().astype(int)\n",
    "        df[col].fillna(-1.0, inplace=True)\n",
    "    else:\n",
    "        df = pd.get_dummies(df, columns=[col], prefix=col, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 1807)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# What is the final shape?\n",
    "print(df.shape)\n",
    "\n",
    "# Any NaN left?\n",
    "print(df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peterp\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\peterp\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#\n",
    "# TEMPORARY DELETE THE TransactionID. It will be needed to join the Identities info\n",
    "#\n",
    "del df['TransactionID']\n",
    "\n",
    "columns = df.columns\n",
    "\n",
    "scaler = StandardScaler(copy=False)\n",
    "#scaler = MinMaxScaler(copy=False)\n",
    "\n",
    "df = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>C1</th>\n",
       "      <th>...</th>\n",
       "      <th>V330_nan</th>\n",
       "      <th>V331_nan</th>\n",
       "      <th>V332_nan</th>\n",
       "      <th>V333_nan</th>\n",
       "      <th>V334_nan</th>\n",
       "      <th>V335_nan</th>\n",
       "      <th>V336_nan</th>\n",
       "      <th>V337_nan</th>\n",
       "      <th>V338_nan</th>\n",
       "      <th>V339_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.274058</td>\n",
       "      <td>0.817417</td>\n",
       "      <td>-2.186194</td>\n",
       "      <td>-0.176293</td>\n",
       "      <td>-1.260537</td>\n",
       "      <td>0.435966</td>\n",
       "      <td>0.375378</td>\n",
       "      <td>-0.101776</td>\n",
       "      <td>-0.10397</td>\n",
       "      <td>-0.100534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.437119</td>\n",
       "      <td>-1.465279</td>\n",
       "      <td>0.285881</td>\n",
       "      <td>-0.176293</td>\n",
       "      <td>-2.159569</td>\n",
       "      <td>0.510346</td>\n",
       "      <td>0.375378</td>\n",
       "      <td>-0.189345</td>\n",
       "      <td>-0.10397</td>\n",
       "      <td>-0.100534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.313275</td>\n",
       "      <td>-1.075396</td>\n",
       "      <td>0.812114</td>\n",
       "      <td>-0.176293</td>\n",
       "      <td>-0.721117</td>\n",
       "      <td>0.547536</td>\n",
       "      <td>0.375378</td>\n",
       "      <td>1.071651</td>\n",
       "      <td>-0.10397</td>\n",
       "      <td>-0.100534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "      <td>0.411335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionAmt     card1     card2     card3     card5     addr1     addr2  \\\n",
       "0       -0.274058  0.817417 -2.186194 -0.176293 -1.260537  0.435966  0.375378   \n",
       "1       -0.437119 -1.465279  0.285881 -0.176293 -2.159569  0.510346  0.375378   \n",
       "2       -0.313275 -1.075396  0.812114 -0.176293 -0.721117  0.547536  0.375378   \n",
       "\n",
       "      dist1    dist2        C1    ...     V330_nan  V331_nan  V332_nan  \\\n",
       "0 -0.101776 -0.10397 -0.100534    ...     0.411335  0.411335  0.411335   \n",
       "1 -0.189345 -0.10397 -0.100534    ...     0.411335  0.411335  0.411335   \n",
       "2  1.071651 -0.10397 -0.100534    ...     0.411335  0.411335  0.411335   \n",
       "\n",
       "   V333_nan  V334_nan  V335_nan  V336_nan  V337_nan  V338_nan  V339_nan  \n",
       "0  0.411335  0.411335  0.411335  0.411335  0.411335  0.411335  0.411335  \n",
       "1  0.411335  0.411335  0.411335  0.411335  0.411335  0.411335  0.411335  \n",
       "2  0.411335  0.411335  0.411335  0.411335  0.411335  0.411335  0.411335  \n",
       "\n",
       "[3 rows x 1806 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df, columns=columns)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.read_csv(\"train_identity.csv\")\n",
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling for Identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_01\n",
    "#ids.id_01.isna().sum()\n",
    "#ids.id_01.value_counts()\n",
    "# No changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_02\n",
    "#ids.id_02.isna().sum()\n",
    "#ids.id_02.max()\n",
    "\n",
    "ids[\"id_02\" + \"_nan\"] = ids[\"id_02\"].isna().astype(int)\n",
    "ids[\"id_02\"].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_03\n",
    "#ids.id_03.isna().sum()\n",
    "#ids.id_03.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_03'], prefix='id_03', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_04\n",
    "#ids.id_04.isna().sum()\n",
    "#ids.id_04.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_04'], prefix='id_04', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_05\n",
    "#ids.id_05.isna().sum()\n",
    "#ids.id_05.value_counts()\n",
    "\n",
    "ids[\"id_05\" + \"_nan\"] = ids[\"id_05\"].isna().astype(int)\n",
    "ids[\"id_05\"].fillna(100.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_06\n",
    "#ids.id_06.isna().sum()\n",
    "#ids.id_06.value_counts()\n",
    "\n",
    "ids[\"id_06\" + \"_nan\"] = ids[\"id_06\"].isna().astype(int)\n",
    "ids[\"id_06\"].fillna(100.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_07\n",
    "#ids.id_07.isna().sum()\n",
    "#ids.id_07.value_counts()\n",
    "#ids.id_07.min()\n",
    "\n",
    "ids[\"id_07\" + \"_nan\"] = ids[\"id_07\"].isna().astype(int)\n",
    "ids[\"id_07\"].fillna(100.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_08\n",
    "#ids.id_08.isna().sum()\n",
    "#ids.id_08.value_counts()\n",
    "#ids.id_08.max()\n",
    "\n",
    "ids[\"id_08\" + \"_nan\"] = ids[\"id_08\"].isna().astype(int)\n",
    "ids[\"id_08\"].fillna(100.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_09\n",
    "#ids.id_09.isna().sum()\n",
    "#ids.id_09.value_counts()\n",
    "\n",
    "ids[\"id_09\" + \"_nan\"] = ids[\"id_09\"].isna().astype(int)\n",
    "ids[\"id_09\"].fillna(100.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_10\n",
    "#ids.id_10.isna().sum()\n",
    "#ids.id_10.value_counts()\n",
    "\n",
    "ids[\"id_10\" + \"_nan\"] = ids[\"id_10\"].isna().astype(int)\n",
    "ids[\"id_10\"].fillna(100.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_11\n",
    "#ids.id_11.isna().sum()\n",
    "#ids.id_11.value_counts()\n",
    "#ids.id_11.min()\n",
    "\n",
    "ids[\"id_11\" + \"_nan\"] = ids[\"id_11\"].isna().astype(int)\n",
    "ids[\"id_11\"].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_12\n",
    "#ids.id_12.isna().sum()\n",
    "#ids.id_12.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_12'], prefix='id_12', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_13\n",
    "#ids.id_13.isna().sum()\n",
    "#ids.id_13.value_counts()\n",
    "\n",
    "ids[\"id_13\" + \"_nan\"] = ids[\"id_13\"].isna().astype(int)\n",
    "ids[\"id_13\"].fillna(100.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_14\n",
    "#ids.id_14.isna().sum()\n",
    "#ids.id_14.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_14'], prefix='id_14', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_15\n",
    "#ids.id_15.isna().sum()\n",
    "#ids.id_15.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_15'], prefix='id_15', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_16\n",
    "#ids.id_16.isna().sum()\n",
    "#ids.id_16.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_16'], prefix='id_16', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_17\n",
    "#ids.id_17.isna().sum()\n",
    "#ids.id_17.value_counts()\n",
    "#ids.id_17.min()\n",
    "\n",
    "ids[\"id_17\" + \"_nan\"] = ids[\"id_17\"].isna().astype(int)\n",
    "ids[\"id_17\"].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_18\n",
    "#ids.id_18.isna().sum()\n",
    "#ids.id_18.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_18'], prefix='id_18', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_19\n",
    "#ids.id_19.isna().sum()\n",
    "#ids.id_19.value_counts()\n",
    "#ids.id_19.min()\n",
    "\n",
    "ids[\"id_19\" + \"_nan\"] = ids[\"id_19\"].isna().astype(int)\n",
    "ids[\"id_19\"].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_20\n",
    "#ids.id_20.isna().sum()\n",
    "#ids.id_20.value_counts()\n",
    "#ids.id_20.min()\n",
    "\n",
    "ids[\"id_20\" + \"_nan\"] = ids[\"id_20\"].isna().astype(int)\n",
    "ids[\"id_20\"].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_21\n",
    "#ids.id_21.isna().sum()\n",
    "#ids.id_21.value_counts()\n",
    "#ids.id_21.min()\n",
    "\n",
    "ids[\"id_21\" + \"_nan\"] = ids[\"id_21\"].isna().astype(int)\n",
    "ids[\"id_21\"].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_22\n",
    "#ids.id_22.isna().sum()\n",
    "#ids.id_22.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_22'], prefix='id_22', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_23\n",
    "#ids.id_23.isna().sum()\n",
    "#ids.id_23.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_23'], prefix='id_23', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_24\n",
    "#ids.id_24.isna().sum()\n",
    "#ids.id_24.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_24'], prefix='id_24', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_25\n",
    "#ids.id_25.isna().sum()\n",
    "#ids.id_25.value_counts()\n",
    "#ids.id_25.min()\n",
    "\n",
    "ids[\"id_25\" + \"_nan\"] = ids[\"id_25\"].isna().astype(int)\n",
    "ids[\"id_25\"].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_26\n",
    "#ids.id_26.isna().sum()\n",
    "#ids.id_26.value_counts()\n",
    "#ids.id_26.min()\n",
    "\n",
    "ids[\"id_26\" + \"_nan\"] = ids[\"id_26\"].isna().astype(int)\n",
    "ids[\"id_26\"].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_27\n",
    "#ids.id_27.isna().sum()\n",
    "#ids.id_27.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_27'], prefix='id_27', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_28\n",
    "#ids.id_28.isna().sum()\n",
    "#ids.id_28.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_28'], prefix='id_28', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_29\n",
    "#ids.id_29.isna().sum()\n",
    "#ids.id_29.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_29'], prefix='id_29', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_30\n",
    "#ids.id_30.isna().sum()\n",
    "#ids.id_30.value_counts()\n",
    "\n",
    "ids[\"id_30\"].fillna(\"Missing\", inplace=True)\n",
    "ids[\"OS_Type\"] = ids.id_30.str.split(\" \").map(lambda x: x[0])\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_30'], prefix='id_30', dummy_na=True)\n",
    "ids = pd.get_dummies(ids, columns=['OS_Type'], prefix='OS_Type', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# id_31\n",
    "#ids.id_31.isna().sum()\n",
    "#list(ids.id_31.value_counts().index)\n",
    "\n",
    "ids[\"id_31\"].fillna(\"Missing\", inplace=True)\n",
    "\n",
    "browser_type = []\n",
    "\n",
    "for i in range(ids.shape[0]):\n",
    "    browser = ids.loc[i, \"id_31\"].lower()\n",
    "    \n",
    "    if (\"chrome\" in browser):\n",
    "        browser_type.append(\"chrome\")\n",
    "    elif(\"safari\" in browser):\n",
    "        browser_type.append(\"safari\")\n",
    "    elif(\"ie\" in browser):\n",
    "        browser_type.append(\"ie\")    \n",
    "    elif(\"safari\" in browser):\n",
    "        browser_type.append(\"safari\")\n",
    "    elif(\"firefox\" in browser):\n",
    "        browser_type.append(\"firefox\")      \n",
    "    elif(\"samsung\" in browser):\n",
    "        browser_type.append(\"samsung\")   \n",
    "    elif(\"edge\" in browser):\n",
    "        browser_type.append(\"edge\")   \n",
    "    elif(\"webview\" in browser):\n",
    "        browser_type.append(\"webview\") \n",
    "    elif(\"opera\" in browser):\n",
    "        browser_type.append(\"opera\")         \n",
    "    elif(\"search\" in browser):\n",
    "        browser_type.append(\"search\")     \n",
    "    elif(\"microsoft\" in browser):\n",
    "        browser_type.append(\"microsoft\") \n",
    "    else:\n",
    "        browser_type.append(browser)\n",
    "        \n",
    "ids = pd.get_dummies(ids, columns=['id_31'], prefix='id_31', dummy_na=True)\n",
    "ids['Browser_Type'] = browser_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_32\n",
    "#ids.id_32.isna().sum()\n",
    "#ids.id_32.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_32'], prefix='id_32', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_33\n",
    "#ids.id_33.isna().sum()\n",
    "#ids.id_33.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_33'], prefix='id_33', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_34\n",
    "#ids.id_34.isna().sum()\n",
    "#ids.id_34.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_34'], prefix='id_34', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_35\n",
    "#ids.id_35.isna().sum()\n",
    "#ids.id_35.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_35'], prefix='id_35', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_36\n",
    "#ids.id_36.isna().sum()\n",
    "#ids.id_36.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_36'], prefix='id_36', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_37\n",
    "#ids.id_37.isna().sum()\n",
    "#ids.id_37.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_37'], prefix='id_37', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# id_38\n",
    "#ids.id_38.isna().sum()\n",
    "#ids.id_38.value_counts()\n",
    "\n",
    "ids = pd.get_dummies(ids, columns=['id_38'], prefix='id_38', dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Identities and Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(df, ids, on=\"TransactionID\", how=\"left\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data[\"TransactionID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.id_01.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.id_01.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### not clear yet what to do after merge.\n",
    "#### only 145K rows will be full\n",
    "#### let's first look at the performance on the Transactions set without Identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(df, labels, stratify=labels, test_size=0.3, random_state=8)\n",
    "\n",
    "X_train = df.iloc[:train_size, :]\n",
    "X_test = df.iloc[train_size:, :]\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#\n",
    "# Gradient Boosting Machine\n",
    "#\n",
    "GBR = GradientBoostingRegressor(random_state=8)\n",
    "\n",
    "parameters_grid = {\n",
    "    \"n_estimators\": [350, 400, 450],\n",
    "    \"min_samples_split\": [2, 3, 4],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "gcv = GridSearchCV(GBR, parameters_grid, scoring='neg_mean_squared_error')\n",
    "gcv.fit(features_train, labels_train)\n",
    "GBR = gcv.best_estimator_\n",
    "print(GBR)\n",
    "print(\"GBR Score:\", gcv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\peterp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\peterp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               925184    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 992,929\n",
      "Trainable params: 992,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def rocauc(y_true, y_pred):\n",
    "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(512, activation='relu', kernel_initializer='normal', input_dim=df.shape[1]))\n",
    "classifier.add(Dropout(0.1))\n",
    "classifier.add(Dense(128, activation='relu', kernel_initializer='normal'))\n",
    "classifier.add(Dropout(0.1))\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='normal'))\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))\n",
    "\n",
    "classifier.compile(optimizer ='adam', loss='binary_crossentropy', metrics =['accuracy', rocauc])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "590540/590540 [==============================] - 79s 133us/sample - loss: 0.0664 - acc: 0.9819 - rocauc: 0.9436\n",
      "Epoch 2/10\n",
      "590540/590540 [==============================] - 79s 134us/sample - loss: 0.0645 - acc: 0.9824 - rocauc: 0.9473\n",
      "Epoch 3/10\n",
      "590540/590540 [==============================] - 80s 135us/sample - loss: 0.0635 - acc: 0.9825 - rocauc: 0.9493\n",
      "Epoch 4/10\n",
      "590540/590540 [==============================] - 80s 135us/sample - loss: 0.0628 - acc: 0.9829 - rocauc: 0.9507\n",
      "Epoch 5/10\n",
      "590540/590540 [==============================] - 80s 135us/sample - loss: 0.0645 - acc: 0.9831 - rocauc: 0.9531\n",
      "Epoch 6/10\n",
      "590540/590540 [==============================] - 80s 136us/sample - loss: 0.0598 - acc: 0.9836 - rocauc: 0.9550\n",
      "Epoch 7/10\n",
      "590540/590540 [==============================] - 81s 137us/sample - loss: 0.0592 - acc: 0.9837 - rocauc: 0.9568\n",
      "Epoch 8/10\n",
      "590540/590540 [==============================] - 81s 137us/sample - loss: 0.0579 - acc: 0.9839 - rocauc: 0.9588\n",
      "Epoch 9/10\n",
      "590540/590540 [==============================] - 80s 136us/sample - loss: 0.0576 - acc: 0.9842 - rocauc: 0.9586\n",
      "Epoch 10/10\n",
      "590540/590540 [==============================] - 82s 138us/sample - loss: 0.0567 - acc: 0.9843 - rocauc: 0.9601\n",
      "Wall time: 13min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b1610c160>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "write_to_submission_file(np.round(predictions, 1), df_test.TransactionID, out_file=\"submission.01.no_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = X_train[y_train.astype(bool).values]\n",
    "X_train_1['Label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_0 = X_train[(1 - y_train).astype(bool).values]\n",
    "X_train_0['Label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for _ in range(50):\n",
    "    sample_X_zeros = X_train_0.sample(14464)\n",
    "    temp_X_train = pd.concat([sample_X_zeros, X_train_1])\n",
    "    temp_X_train = temp_X_train.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    temp_y_train = temp_X_train['Label']\n",
    "    del temp_X_train['Label']\n",
    "    \n",
    "    classifier.fit(temp_X_train, temp_y_train, batch_size=512, epochs=5)\n",
    "\n",
    "# NN Performance check\n",
    "print(\"Accuracy on Test set:\")\n",
    "predictions = classifier.predict(X_test)\n",
    "print(roc_auc_score(y_test, np.around(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, np.around(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(accuracy_score(y_test, np.around(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for x in predictions:\n",
    "    if (x > 0.5):\n",
    "        count = count + 1\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
